{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7946c46b",
   "metadata": {},
   "source": [
    "![Python](https://img.shields.io/badge/python-3.9-blue)\n",
    "![Status: Pending Migration](https://img.shields.io/badge/status-pending%20migration-orange)\n",
    "\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# 📖 Classification\n",
    "\n",
    "[🧭 Objective](#objective)  \n",
    "- [📌 What is Classification?](#what-is-classification)  \n",
    "- [📦 Use Cases](#classification-use-cases)  \n",
    "\n",
    "[📂 Data Setup](#data-setup)  \n",
    "- [📥 Load Dataset](#load-dataset)  \n",
    "- [🧹 Preprocessing](#preprocessing)\n",
    "\n",
    "[🧪 Baseline Model](#baseline-model)  \n",
    "- [📈 Baseline Classifier](#baseline-classifier)  \n",
    "- [📊 Metrics to Benchmark](#baseline-metrics)\n",
    "\n",
    "[🔍 Models](#models)\n",
    "- [📊 Logistic Regression](#logistic-regression)\n",
    "- [🧮 Naive Bayes](#naive-bayes)\n",
    "- [🌳 Decision Tree](#decision-tree)\n",
    "- [🌲 Random Forest](#random-forest)\n",
    "- [🚀 XGBoost](#xgboost)\n",
    "- [🎯 KNN (K-Nearest Neighbors)](#knn)\n",
    "- [📈 SVM (Support Vector Machines)](#svm)\n",
    "- [🧠 Neural Network](#neural-net)\n",
    "\n",
    "[📊 Evaluation & Comparison](#evaluation)  \n",
    "- [📉 Confusion Matrix](#confusion-matrix)  \n",
    "- [📈 ROC Curve / AUC](#roc-auc)  \n",
    "- [📏 Precision / Recall / F1](#prf-metrics)  \n",
    "- [📋 Model Comparison Table](#comparison-table)\n",
    "\n",
    "<hr style=\"border: none; height: 1px; background-color: #ddd;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6e3d2",
   "metadata": {},
   "source": [
    "<a id=\"objective\"></a>\n",
    "# 🧭 Objective\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafdd70",
   "metadata": {},
   "source": [
    "<a id=\"what-is-classification\"></a>\n",
    "#### 📌 What is Classification?\n",
    "\n",
    "<details><summary><strong>📖 Click to Expand</strong></summary>\n",
    "Classification is a type of supervised machine learning where the goal is to predict a categorical label for an observation. Given a set of features (input data), the model tries to assign the observation to one of several predefined classes. Common examples of classification problems include:\n",
    "- **Spam detection**: Classifying emails as spam or not.\n",
    "- **Customer churn prediction**: Classifying customers as likely to leave (churn) or stay based on their activity.\n",
    "- **Image recognition**: Classifying images into categories, like identifying animals, vehicles, etc.\n",
    "\n",
    "In classification, the output is discrete (e.g., 'spam' vs 'not spam', 'churn' vs 'no churn'). This contrasts with regression, where the output is continuous (e.g., predicting a house price).\n",
    "\n",
    "##### Key Points\n",
    "- Supervised learning approach.\n",
    "- Used for predicting categories.\n",
    "- Output is discrete (binary or multiclass).\n",
    "- Examples: email classification, disease diagnosis, fraud detection.\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8616d21",
   "metadata": {},
   "source": [
    "<a id=\"classification-use-cases\"></a>\n",
    "#### 📦 Use Cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4415e",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f37c7",
   "metadata": {},
   "source": [
    "<a id=\"data-setup\"></a>\n",
    "# 📂 Data Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09beb6",
   "metadata": {},
   "source": [
    "<a id=\"load-dataset\"></a>\n",
    "#### 📥 Load Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c540ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning and Model Evaluation\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Statistical and Other Utilities\n",
    "from scipy.stats import zscore\n",
    "from termcolor import colored\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faf2c74",
   "metadata": {},
   "source": [
    "<details><summary><strong>📖 Click to Expand</strong></summary>\n",
    "In this section, we will begin by preparing the dataset. For simplicity, we'll use a simulated classification dataset generated using the `make_classification` function from `sklearn`. This allows us to create a synthetic dataset that is suitable for practicing classification tasks.\n",
    "\n",
    "We will simulate a dataset with the following properties:\n",
    "- 1000 samples (observations)\n",
    "- 10 features (predictors)\n",
    "- 2 informative features (ones that help in prediction)\n",
    "- 2 classes (binary classification problem)\n",
    "\n",
    "Let's generate and take a look at the data.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca7b755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.964799</td>\n",
       "      <td>-0.066449</td>\n",
       "      <td>0.986768</td>\n",
       "      <td>-0.358079</td>\n",
       "      <td>0.997266</td>\n",
       "      <td>1.181890</td>\n",
       "      <td>-1.615679</td>\n",
       "      <td>-1.210161</td>\n",
       "      <td>-0.628077</td>\n",
       "      <td>1.227274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.916511</td>\n",
       "      <td>-0.566395</td>\n",
       "      <td>-1.008614</td>\n",
       "      <td>0.831617</td>\n",
       "      <td>-1.176962</td>\n",
       "      <td>1.820544</td>\n",
       "      <td>1.752375</td>\n",
       "      <td>-0.984534</td>\n",
       "      <td>0.363896</td>\n",
       "      <td>0.209470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.109484</td>\n",
       "      <td>-0.432774</td>\n",
       "      <td>-0.457649</td>\n",
       "      <td>0.793818</td>\n",
       "      <td>-0.268646</td>\n",
       "      <td>-1.836360</td>\n",
       "      <td>1.239086</td>\n",
       "      <td>-0.246383</td>\n",
       "      <td>-1.058145</td>\n",
       "      <td>-0.297376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.750412</td>\n",
       "      <td>2.023606</td>\n",
       "      <td>1.688159</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>-1.607661</td>\n",
       "      <td>0.184741</td>\n",
       "      <td>-2.619427</td>\n",
       "      <td>-0.357445</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.190039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.224726</td>\n",
       "      <td>-0.711303</td>\n",
       "      <td>-0.220778</td>\n",
       "      <td>0.117124</td>\n",
       "      <td>1.536061</td>\n",
       "      <td>0.597538</td>\n",
       "      <td>0.348645</td>\n",
       "      <td>-0.939156</td>\n",
       "      <td>0.175915</td>\n",
       "      <td>0.236224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0   0.964799  -0.066449   0.986768  -0.358079   0.997266   1.181890   \n",
       "1  -0.916511  -0.566395  -1.008614   0.831617  -1.176962   1.820544   \n",
       "2  -0.109484  -0.432774  -0.457649   0.793818  -0.268646  -1.836360   \n",
       "3   1.750412   2.023606   1.688159   0.006800  -1.607661   0.184741   \n",
       "4  -0.224726  -0.711303  -0.220778   0.117124   1.536061   0.597538   \n",
       "\n",
       "   Feature_7  Feature_8  Feature_9  Feature_10  Target  \n",
       "0  -1.615679  -1.210161  -0.628077    1.227274       0  \n",
       "1   1.752375  -0.984534   0.363896    0.209470       1  \n",
       "2   1.239086  -0.246383  -1.058145   -0.297376       1  \n",
       "3  -2.619427  -0.357445  -1.473127   -0.190039       0  \n",
       "4   0.348645  -0.939156   0.175915    0.236224       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating a classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_classes=2, random_state=42)\n",
    "target_col = 'Target'\n",
    "\n",
    "# Converting to a DataFrame for easier handling\n",
    "df = pd.DataFrame(X, columns=[f\"Feature_{i}\" for i in range(1, 11)])\n",
    "df[target_col] = y\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28407bd",
   "metadata": {},
   "source": [
    "<a id=\"data-characteristics-dictionary\"></a>\n",
    "\n",
    "#### 📊 Data Characteristics Dictionary\n",
    "\n",
    "<details><summary><strong>📖 Click to Expand Explanation</strong></summary>\n",
    "\n",
    "This section initializes the **data characteristics dictionary**, which will store various metadata about the dataset, including details about the target variable, features, data size, and linear separability.\n",
    "\n",
    "The dictionary contains the following key sections:\n",
    "\n",
    "1. **🎯 Target Variable**:\n",
    "   - **Type**: Specifies whether the target variable is **binary** or **multiclass**.\n",
    "   - **Imbalance**: Indicates whether the target variable has **class imbalance**.\n",
    "   - **Class Imbalance Severity**: Specifies the severity of the imbalance (e.g., **high**, **low**).\n",
    "\n",
    "2. **🔧 Features**:\n",
    "   - **Type**: Describes the type of features in the dataset (e.g., **categorical**, **continuous**, or **mixed**).\n",
    "   - **Correlation**: Indicates the correlation between features (e.g., **low**, **medium**, **high**).\n",
    "   - **Outliers**: Flag to indicate whether **outliers** are detected in the features.\n",
    "   - **Missing Data**: Tracks the percentage of **missing data** or flags missing values.\n",
    "\n",
    "3. **📈 Data Size**:\n",
    "   - **Size**: Contains the **number of samples** (rows) and **number of features** (columns).\n",
    "\n",
    "4. **🔍 Linear Separability**:\n",
    "   - **Linear Separability**: States whether the classes are **linearly separable** (True or False).\n",
    "\n",
    "This dictionary will be updated dynamically as we analyze the dataset in subsequent steps. It serves as a **summary of key dataset properties** to help guide further analysis and modeling decisions.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73753c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data characteristics dictionary\n",
    "data_characteristics = {\n",
    "    \"target_variable\": {\n",
    "        \"type\": None,  # \"binary\", \"multiclass\"\n",
    "        \"imbalance\": None,  # True if imbalanced, False otherwise\n",
    "        \"class_imbalance_severity\": None  # e.g., \"high\", \"low\"\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"type\": None,  # \"categorical\", \"continuous\", \"mixed\"\n",
    "        \"correlation\": None,  # \"low\", \"medium\", \"high\"\n",
    "        \"outliers\": None,  # True if outliers detected, False otherwise\n",
    "        \"missing_data\": None  # Percentage of missing data or boolean\n",
    "    },\n",
    "    \"data_size\": None,  # Size of dataset (samples, features)\n",
    "    \"linear_separability\": None  # True if classes are linearly separable\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffb3b8",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "#### 🧹 Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953ec674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data split complete:\n",
      "Train size: 800, Test size: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=target_col)\n",
    "y = df[target_col]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"✅ Data split complete:\")\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77810fb9",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be293f5",
   "metadata": {},
   "source": [
    "<a id=\"baseline-model\"></a>\n",
    "# 🧪 Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d9e15",
   "metadata": {},
   "source": [
    "<a id=\"baseline-classifier\"></a>\n",
    "#### 📈 Baseline Classifier\n",
    "\n",
    "<details><summary><strong>📖 Click to Expand </strong></summary>\n",
    "\n",
    "In this section, we define the **baseline model** for the classification task. The baseline model is typically a **dummy model** that can be used to compare against more sophisticated models. Here, we use the **DummyClassifier**, which predicts the majority class, to set a baseline performance.\n",
    "\n",
    "The baseline model will help us assess if more advanced models (e.g., Random Forest, SVM) are making meaningful improvements over a simple strategy.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82a6bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Fit a dummy classifier as a baseline\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")  # or try \"stratified\", \"uniform\"\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79df02",
   "metadata": {},
   "source": [
    "<a id=\"baseline-metrics\"></a>\n",
    "#### 📊 Metrics to Benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c780d645",
   "metadata": {},
   "source": [
    "<details><summary><strong>📖 Click to Expand</strong></summary>\n",
    "\n",
    "- **Accuracy**: Overall correctness. Misleading when classes are imbalanced.\n",
    "- **Precision**: Of predicted positives, how many are truly positive? Important when false positives are costly.\n",
    "- **Recall**: Of actual positives, how many did we catch? Crucial when missing positives is expensive.\n",
    "- **F1 Score**: Harmonic mean of precision and recall. Useful when you care about balance.\n",
    "- **ROC AUC**: Probability a random positive ranks above a random negative. Good for probability-based classifiers.\n",
    "\n",
    "We'll log all metrics per model to enable direct comparisons during tuning or model selection.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d488821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Technical Output (Classification Report)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.50       200\n",
      "   macro avg       0.25      0.50      0.33       200\n",
      "weighted avg       0.25      0.50      0.33       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashrithreddy/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ashrithreddy/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ashrithreddy/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Technical output\n",
    "print(\"📉 Technical Output (Classification Report)\\n\")\n",
    "print(classification_report(y_test, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "453c2cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Business-Friendly Summary:\n",
      "- Accuracy  :  50.00% → Overall correctness. How many total predictions were right.\n",
      "- Precision :  50.00% → Of the cases we predicted as '0', how many were actually '0'.\n",
      "- Recall    : 100.00% → Of all the actual '0' cases, how many did we correctly identify.\n",
      "- F1 Score  :  66.67% → A balance between Precision and Recall. Higher means more reliable.\n"
     ]
    }
   ],
   "source": [
    "# Determine positive class label\n",
    "positive_class = y_train.unique()[1] if len(y_train.unique()) == 2 else 1\n",
    "\n",
    "# Compute metrics\n",
    "acc  = accuracy_score(y_test, y_pred_dummy)\n",
    "prec = precision_score(y_test, y_pred_dummy, pos_label=positive_class, average='binary', zero_division=0)\n",
    "rec  = recall_score(y_test, y_pred_dummy, pos_label=positive_class, average='binary', zero_division=0)\n",
    "f1   = f1_score(y_test, y_pred_dummy, pos_label=positive_class, average='binary', zero_division=0)\n",
    "\n",
    "# Print with padded % values to align arrows\n",
    "print(\"\\n📊 Business-Friendly Summary:\")\n",
    "print(f\"- Accuracy  : {acc :>7.2%} → Overall correctness. How many total predictions were right.\")\n",
    "print(f\"- Precision : {prec:>7.2%} → Of the cases we predicted as '{positive_class}', how many were actually '{positive_class}'.\")\n",
    "print(f\"- Recall    : {rec :>7.2%} → Of all the actual '{positive_class}' cases, how many did we correctly identify.\")\n",
    "print(f\"- F1 Score  : {f1  :>7.2%} → A balance between Precision and Recall. Higher means more reliable.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5a36b",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb56812",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "# 🔍 Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b01510",
   "metadata": {},
   "source": [
    "<a id=\"logistic-regression\"></a>\n",
    "#### 📊 Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680be07",
   "metadata": {},
   "source": [
    "<a id=\"naive-bayes\"></a>\n",
    "#### 🧮 Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a831589",
   "metadata": {},
   "source": [
    "<a id=\"decision-tree\"></a>\n",
    "#### 🌳 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad987ee3",
   "metadata": {},
   "source": [
    "<a id=\"random-forest\"></a>\n",
    "#### 🌲 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb6069",
   "metadata": {},
   "source": [
    "<a id=\"xgboost\"></a>\n",
    "#### 🚀 XGBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a4b23",
   "metadata": {},
   "source": [
    "<a id=\"knn\"></a>\n",
    "#### 🎯 KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550a922",
   "metadata": {},
   "source": [
    "<a id=\"svm\"></a>\n",
    "#### 📈 SVM (Support Vector Machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089ef7a",
   "metadata": {},
   "source": [
    "<a id=\"neural-net\"></a>\n",
    "#### 🧠 Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ee97d",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabc42a",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "# 📊 Evaluation & Comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29501be6",
   "metadata": {},
   "source": [
    "<a id=\"confusion-matrix\"></a>\n",
    "#### 📉 Confusion Matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b24059",
   "metadata": {},
   "source": [
    "<a id=\"roc-auc\"></a>\n",
    "#### 📈 ROC Curve / AUC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f751ffa",
   "metadata": {},
   "source": [
    "<a id=\"prf-metrics\"></a>\n",
    "#### 📏 Precision / Recall / F1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61653b60",
   "metadata": {},
   "source": [
    "<a id=\"comparison-table\"></a>\n",
    "#### 📋 Model Comparison Table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02091d",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
